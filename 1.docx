技术路线
Background：基于智能算法的毁伤评估研究：在有限的毁伤测量数据和巨量的毁伤计算数据的基础上结合规划的scikit-learn、pytorch和paddlePaddle等机器学习算法框架，探索性开展基于智能算法的毁伤评估研究，实现我军武器弹药对敌方任意目标的毁伤效应的高效计算，有效获取敌方目标毁伤情况，支撑OODA作战环路中的火力筹划。
基于智能算法的毁伤评估技术研究
近年来，随着无人系统、人工智能等领域的快速发展及硬件水平的提升，智能化、自主化技术在军事方面受到了各国的高度关注，相关的理论和技术发展迅速。现代战争中，无人自主作战方式也势必成为一种主要手段，因此，各军事强国均在该方向上展开大量实验和技术攻关，力争将该技术应用于实战之中[1]。面对具有高目标价值和强防御能力的敌方目标威胁，无人自主作战成为一种有效的策略，但是这种作战方式对于战场的环境观测和目标状态感知能力也提出了新的挑战[2]。因此，在作战场景下，军事目标的毁伤检测和评估变得越来越重要，准确和及时的毁伤评估可以为决策提供有价值的信息，帮助指挥官制定更加有效的作战计划和战术[3]。然而，由于毁伤测量数据有限、巨量的毁伤计算数据利用不充分，以及战场环境的复杂性和不确定性，基于专家知识的传统毁伤评估方法往往存在准确性和效率方面的限制，由于其过度依赖于人的主观意识，这类方法存在着主观性和不确定性的问题。在战场环境中，人类观察和判断的准确性和效率往往受到环境、时间和人员等因素的影响，难以保证评估结果的准确性和及时性。而传统基于图像变化检测的毁伤评估方法主要用于固定目标的毁伤评估，对于具有运动能力的移动目标，受打击后并不意味着完全丧失运动能力，使得图像配准过程受限，因此基于图像的变化检测对移动目标的适用性不高，无法满足实际的作战需求[11]。
近年来，随着计算机视觉和机器学习技术的快速发展，基于深度学习和图像分析等智能算法的毁伤评估系统引起了越来越多人的关注。基于卷积神经网络(Convolutional Neural Network, CNN)的方法在图像领域取得了巨大成功，特别在目标检测和分类方面[12]。CNN能够从毁伤数据中学习并提取深层次的语义特征，且满足在线实时要求，因此基于神经网络的智能算法的毁伤评估技术研究不断涌现，张宗腾等[13]提出了基于改进BP神经网络的目标毁伤评估方法，通过构建目标毁伤树、优化遗传算法参数和BP神经网络权重，实现对飞机系统目标毁伤效果的快速、准确评估。目前基于神经网络的目标威胁评估[11]、抗毁伤能力评估[14]和建筑物毁伤评估[15]已经取得了良好的效果。基于神经网络的毁伤评估可以有效地从传感器捕获的图像或视频中提取和分析毁伤信息，并提供准确和客观的毁伤评估结果。相比传统的毁伤评估方法，基于深度学习的毁伤评估系统具有更高的准确性和效率，可以大大提高作战行动中的决策制定效率和准确性。然而，由于毁伤测量数据有限且巨量的毁伤计算数据利用不充分，导致现有基于智能算法的毁伤评估技术在实际战场环境下存在无法识别潜在问题、评估结果不够精准和毁伤效应计算不够高效等问题。
总体研究方案（半页）
本研究提出了一种基于深度学习和模糊层次分析的智能算法的双阶段毁伤评估技术，旨在解决传统方法和卷积神经网络方法在目标毁伤评估上的局限性。通过对可见光、红外传感器实时捕获的图像或视频信息等毁伤测量数据进行分析，通过毁伤部件分类器对毁伤特征进行分类，最后，建立多种类别的毁伤评估权重体系，依据不同类别对象的毁伤树判据进行判别，为决策者提供准确和客观的毁伤评估结果。受到两阶段神经网络评估方法的启发，本研究提出的毁伤评估系统采用基于分层目标检测框架设计，目标检测子系统包括两个层级：第一层级使用带有坐标注意力机制(Coordinate Attention, CA)的轻量化视觉神经网络进行目标检测，专注于检测和定位毁伤评估对象，而第二层级基于本研究设计的基于毁伤特征的关键区域提取机制，利用决策树和匈牙利算法相结合的毁伤部件分类器，对每个目标的毁伤区域进分类，并提供整体的毁伤评估结果。毁伤评估子系统利用引入三角模糊数的模糊层次分析法和BP神经网络，为不同类别对象制定毁伤评估权重体系，结合不同对象的结构特性建立毁伤树判据，对前一阶段提取到的毁伤特征和毁伤类别进行综合考虑，输出客观的毁伤评估结果并提高毁伤效应的计算能力。
具体技术路线及关键技术（5页）
针对毁伤测量数据有限和巨量的毁伤计算数据利用不充分，以及不确定环境作战场景下的打击目标毁伤评估问题，要求对目标实现快速识别的同时，还能保证准确的做出毁伤评估的要求，实现我军武器弹药对敌方任意目标的毁伤效应的高效计算，本研究构建了一套基于深度学习和模糊层次分析的智能算法的毁伤评估方法，如图1所示。整个毁伤评估系统可分为两个子系统，分别为目标检测子系统和毁伤评估子系统，在目标检测子系统中，使用带有注意力机制的Yolov5目标检测算法建立了由多个检测头组成的双层级图像检测网络，用于作战场景下不同类别对象的部件、毁伤检测，实现我军武器弹药对敌方任意目标的毁伤效应的高效计算；在毁伤评估子系统中，依据打击对象的结构特性等基本要素，建立了基于模糊层次分析法的毁伤指标体系，并构建符合其结构特性的毁伤树，实现被检测对象毁伤情况的快速准确评估，并根据各个毁伤等级构建不同的反馈机制，输出毁伤评估结果，，有效获取敌方目标毁伤情况。
1）带有注意力机制的毁伤双层检测系统
为了获取作战场景下，战场环境的态势信息以及打击对象的毁伤信息，实际战场环境中需要依赖多种传感器和技术的协同支持，包括使用高分辨率图像、遥感数据、雷达数据等来获得可信的毁伤测量数据。在这一过程中，所需的硬件支持可能涉及到多种设备，如RGB相机、事件相机、红外相机、激光雷达等。然而，这些毁伤测量数据是有限的，针对这些多样但有限的毁伤测量信息来源，本研究提出了一种带有注意力机制的Yolov5双层检测网络作为目标检测子系统，如图2所示。该子系统由两个层级组成，分别对打击对象进行关键区域的提取和毁伤部件的识别。本研究利用第一层级网络提取整张输入图像中打击对象的关键区域，在此基础上构建第二层级网络对提取到的关键区域进行部件和毁伤的检测，通过引入CA注意力机制的方法，提高Yolov5检测头的准确性。为了提取关键区域，本研究设计了一种带有注意力机制的关键区域提取器，以减少整体图像中非关键区域的信息冗余，针对毁伤部件的分类问题，提出一种基于匈牙利算法的毁伤部件分类器，该分类器利用部件框和毁伤框的IOU进行线性匹配，以获取毁伤的类别，并通过两框之间的相对面积量化毁伤程度。
毁伤测量数据关键区域提取机制
由于毁伤测量数据有限且战场环境错综复杂，通过可见光或者红外相机检测到的图像存在大量干扰，又因为空对地的检测场景下，打击对象的部件和毁伤部位在相机视角下过于渺小，特征信息不明显，会导致部件和毁伤部位大量的误检，大大降低了后续毁伤评估的准确性，在这一背景下，本研究采取了针对小目标的毁伤评估策略，小目标即为在整个图像中占据面积较小的目标。实际上，小目标在实际的毁伤评估任务中十分重要，因为作战场景下的毁伤图像往往由无人机在高空远距离进行拍摄以进行毁伤评估。对于该问题，本研究在系统的第一层级和第二层级之间设计了一个目标关键区域提取器，得到被检测对象的关键区域，作为下一级检测头的输入，以达到第二层级进行部件毁伤检测时去除冗余信息的效果，有利于对小目标的检测，并且在经过提取器后的二层网络训练过程中，仅使用目标部件类别的标签作为监督信息，减少特征的发散性。
关键区域提取器输入为第一层级检测头提取到视场中所有对象候选框的位置{P_1,P_2,…,P_N }、类别{C_1,C_2,…,C_N }、置信度{ε_1,ε_2,…,ε_N}和对象个数n_1，输出多个五维向量{x_1^i,y_i^i,x_2^i,y_2^i,C_0^i}。其中，P_i为第i个对象候选框左上角和右下角坐标值集合，C_i表示数组中第i个对象的类别信息，同理，ε_i表示第i个候选框的置信度值，x_1^i,y_i^i,x_2^i,y_2^i表示第i个候选框的左上角和右下角坐标值，用于提取打击对象关键区域的图像信息，C_0^i表示提取到第i个关键区域所属的一级类别，其作用为将提取到的关键区域送入对应类别的部件检测头中进行第二层级的部件、毁伤检测。
提取器接收到目标检测头输出的所有打击对象候选框坐标x_1,y_1,x_2,y_2、对象类别C_i以及置信度ε_i，若ε_i满足:
ε_i≥(∑_(j=1)^n▒ε_j )/n_1 ≥α
则认为第i个检测结果是可信的，将该打击对象的检测信息保留，否则认为是误检，将其剔除，由于不同的可见光、红外相机获取的图像质量不同，结合不同战场环境对检测效果也有一定影响，因此这里设置参数α为平均置信度的下限阈值。对于每一个保留的候选框的x_1^i,y_i^i,x_2^i,y_2^i和C_0^i，将其作为部件和毁伤检测对象的关键区域信息返回。接着，对每一个x_1^i,y_i^i,x_2^i,y_2^i所表示的关键区域从第一层级的输入图像中剪切出来，作为第二层级的输入。由于实际作战场景下，存在多种目标类型，如飞机、车辆等等，因此目标检测系统的第二层级由多个类别不同的部件检测头组成，通过提取器输出的每一个关键区域所属类别C_0^i将不同类别的输入送入与之对应的部件检测头，进行部件和毁伤的检测。
基于CA注意力机制的Yolov5检测头
虽然在目标检测子系统的层级一和层级二之间添加了关键区域提取器以提高对部件和毁伤的检测精度，减小误检率，但由于Yolov5检测头的检测性能与训练数据集，作战场景信息的复杂程度和干扰因素，检测的目标的大小等存在一定关系，因此检测头存在一定的局限性，面对恶劣的条件时，会降低整个检测系统的检测性能，对此，本研究对于层级一和层级二中所使用的Yolov5检测头均添加了注意力机制，使得检测头选择性地关注重要信息，合理利用有限的视觉信息处理资源。由于在作战场景下，需要准确、及时的实现打击对象的毁伤评估，这就要求检测网络的轻量级以提升检测的速度，因此该检测系统两个层级的Yolov5s检测头均加入CA注意力机制以实现在轻量级网络的基础上更好地识别打击对象和毁伤部件。如图3所示，CA注意力机制通过将位置信息嵌入通道注意力中，从而捕捉空间选择性的注意力图。与通道注意力不同，通道注意力通过2D全局池化将特征张量转换为单个特征向量，而CA注意力将通道注意力分解为两个1D特征编码过程，分别沿着两个空间方向聚合特征。这样，可以捕捉到一个空间方向上的长期依赖性，同时保留另一个空间方向上的精确位置信息。生成的特征图被编码成一对方向感知和位置敏感的注意力图，可以互补地应用于输入特征图，增强感兴趣对象的表示。
 
对Yolov5s网络输入到CA模块大小为W×H×C的特征图进行宽度W和高度H的编码操作并进行平均池化得：
z_c^h (h)=1/W ∑_(0≤i≤W)▒〖x_c (h,i)〗
z_c^h (w)=1/H ∑_(0≤j≤H)▒〖x_c (j,W)〗
其中，z_c^h (h)和z_c^h (w)分别为输入特征图高度h处和宽度w处的编码输出，输出的中间特征图经过CA模块的连接、卷积、激活和拆分后可以将该特征图的特征分切为两个单独的张量z^h和z^w，为了使两个张量具有和输入特征图一样的通道数C，继续用两个1×1的卷积F_h和F_w进行变换操作，如式(5)和(6)所示：
g^h=σ(F_h (z^h ))
g^w=σ(F_w (z^w))
其中σ(∙)为sigmoid激活函数，g^h和g^w分别为中间特征图拆分后与输入特征有相同通道数C的H和W方向的特征张量，将其作为输出特征的注意力权重，得到CA注意力模块的特征图像输出：
y_c (i,j)=x_c (i,j)×g_c^h (i)×g_c^w (j)
其中c表示通道数，g_c^h (i)表示H方向上第i个位置的注意力权重，g_c^w (j)表示W方向上第j个位置的注意力权重，y_c (i,j)为第c个通道上(i,j)处的输出特征，将其输出到Yolov5网络的后半部分中。CA注意力简单且灵活，几乎不需要额外的计算资源，具体来说，CA注意力的计算资源主要包括两个方面：1D全局池化操作和注意力图生成。1D全局池化操作是对输入特征进行聚合，它的计算复杂度与输入特征的大小成线性关系。注意力图生成是通过一些简单的计算来生成注意力图，计算复杂度较低。与通道注意力方法相比，CA注意力不需要进行复杂的压缩操作，也不需要进行全局平均池化操作。因此，其计算开销较小，可以轻松地插入到轻量级检测网络中，而不会显著增加计算资源的需求。
在两个层级的检测头中，本研究将CA注意力机制应用于Yolov5s模型的主干网络中，如图4所示。对于打击对象和毁伤部件的检测保持了较高的检测速度的同时在精度上也有了明显的提升，减少了打击对象以及毁伤部件的误检和漏检，并且有利于检测小目标。
 
基于决策树和匈牙利算法的毁伤分类器
对于毁伤部件的检测和分类，将提取到的关键区域根据其对应的类别C_0^i分别送入对应的部件检测头中，本研究训练了多个带有CA注意力模块的Yolov5s检测头，分别用于检测不同类别对象的部件和毁伤信息。在检测头的训练过程中，不同检测头使用不同对象的部件类别的标签作为监督信息，这样做的好处是每个检测头训练过程中，仅专注于该类别的类内特征信息，提高不同对象的部件和毁伤的检测准确率。提取的关键区域送入部件检测头，输出部件框和毁伤框的位置P_com、P_dmg；置信度ε_com、ε_dmg  ；部件类别C_com及毁伤框和部件框个数m、n_2，其中:
P_com={x_com1,y_com1,x_com2,y_com2 },P_dmg={x_dmg1,y_dmg1,x_dmg2,y_dmg2}
正常情况下，YOLOv5检测头输出部件类别C_com的同时也会输出毁伤框的类别，本研究将得到的所有毁伤框均设置为同一类别，并未进行部件的类内划分，这是因为在作战场景下，各类对象的毁伤数据由于军事原因不易采集，样本量不足，并且各部位毁伤难以直接通过特征区分，直接利用YOLOv5检测头对毁伤区域进行多分类，会出现较多毁伤部件类别的误检，因此在数据集的处理上，对所有部件的毁伤区域仅使用单一标签作为监督信息，使得检测头输出的毁伤类别为一常数η。由此，本研究在部件检测头后设计了一个毁伤分类器，该分类器不仅可以基于匈牙利算法完成毁伤区域和对应部件的匹配任务，得到检测区域内所有毁伤框对应的部件类别C_dmg，而且可以输出各毁伤部件的毁伤程度量化值，这里C_dmg为一个m×1的数组，m为该检测区域中毁伤框的个数，其元素为C_dmg^i，表示每一个毁伤框的类别，当第i个毁伤框没有匹配的部件框时，该毁伤框的类别为未知类别，用C_dmg^i=0表示；第i个毁伤框与第j个部件框相匹配时，该毁伤框的类别等于C_comj，这里C_comj为匹配的部件框j的类别，为一个常数，由Yolov5检测头输出且C_comj≥1。
对于毁伤区域和对应部件的匹配，分类器将毁伤框和部件框之间的IOU，也就是两框之间的重叠程度作为分类度量指标，即：
IOU(P_dmg^i,P_com^j )=(P_dmg^i∩P_com^j)/(P_dmg^i∪P_com^j )
其中，P_dmg^i表示该检测区域中第i个毁伤框区域，P_com^j表示该检测区域中第j个部件框区域，IOU(P_dmg^i,P_com^j )为第i个毁伤框和第j个部件框的重叠程度。本研究令每个毁伤框与部件框之间的IOU作为毁伤框与部件框匹配代价的度量值，构造出该检测区域中的毁伤部件匹配的最小化代价矩阵C=[c_ij],并且定义：
c_ij=1-IOU(P_dmg^i,P_com^j)
将该矩阵送入匈牙利模块中进行线性匹配，输出毁伤框与部件框的最优匹配，从而完成毁伤框的分类。匈牙利算法是一种最佳任务分配方法，其基本思想为通过对分配任务的最小化代价矩阵进行适当的变换，将原问题的最小代价转化为新问题的最大代价，即将线性分配问题转化为最大匹配问题进行求解。
匈牙利对由毁伤框和部件框的IOU为度量值的最小化代价矩阵C进行变换，得到变换矩阵M=[m_ij]，其中m_ij=-c_ij-u_i-v_j，u_i为第i行的最小值，v_j为第j列的最小值。对于变换矩阵M，采用匈牙利算法进行最大匹配，最后，将最大匹配的结果反转，得到原问题的最优匹配。
毁伤区域及部件经过分配后，可以得到检测图像中毁伤区域的具体类别，由于匈牙利算法的时间复杂度为O(n^3)，因此可以使分类器在短时间内完成毁伤框的分类。对于各毁伤部件的毁伤程度量化值，分类器将匹配的毁伤框和部件框之间的面积比作为毁伤特征，即：
θ_ij=(|x_dmg1^i-x_dmg2^i |×|y_dmg1^i-y_dmg2^i |)/(n|x_com1^i-x_com2^i |×|y_com1^i-y_com2^i | )
其中，θ_ij表示毁伤特征，为第i个毁伤框与第j个部件框的面积之比，i和j分别为经过匈牙利模块匹配后的毁伤框和部件框索引值。匈牙利模块并不能解决所有毁伤框的分类问题，因为在分类过程中还存在一些特殊情况，例如部件毁伤严重导致毁伤框对应的部件框检测不到，由于视角问题导致毁伤框与部件框重叠等等，对于这些特殊情况，无法利用匈牙利模块进行匹配，因此，在毁伤分类器中，本研究对这些情况进行了统一处理，得到毁伤分类器具体算法流程。
对于检测系统第二层级输入的每一张关键区域图像，该分类器实现了不依赖于数据驱动的毁伤部件分类任务，对于不同作战场景下的小样本毁伤分类问题，依据检测框之间的位置关系对毁伤部件进行合适的分类，输出毁伤所属的部件类别C_dmg以及各部件毁伤特征θ_ij。
基于三角模糊层次分析法的毁伤等级评估方法
对于目标检测系统输出的毁伤类别Cdmg以及各部件毁伤特征θij，本研究将其作为目标整体毁伤评估的判断依据进行评估。常用的评价方法为层次分析法，但是在构造判别矩阵过程中，利用固定的判别值对各因素进行两两比较得出相对重要性并用数值标度，无法充分考虑各个因素之间的复杂关系，存在主观性较强的问题，对此，本研究构建了图7所示的基于三角模糊层次分析法的毁伤评估系统，针对不同对象建立由各部件及其毁伤程度构成的毁伤树模型，并对每一类对象制定特定的毁伤体系权重，结合目标检测子系统的输出结果，得到不同类别毁伤对于评估对象整体的毁伤等级，为后续的打击决策提供作战依据。
毁伤树判据的构建
毁伤树作为一种层次化的结构模型，用于描述各评价指标的关系、重要性，以及各因素对于整体指标的影响，在毁伤评估过程中，不同对象毁伤树判据是否合理直接影响毁伤评估的准确度，图8为目标毁伤因素结构模型。
在高空对地的任务场景中，提取的图像信息往往受限于小目标的分辨率，难以区分过于细粒度的部件特征，并且提取到的毁伤特征的位置不一定与被毁伤部件的准确位置相符。为了解决该问题，本研究针对战斗机、装甲车类目标，综合考虑各部件毁伤因素和重要性，分别建立毁伤树判据。以战斗机为例，将战斗机系统按照其结构特性分为两个模块，分别为控制模块、动力模块，其毁伤树模型如图9所示。
动力模块在可见光和红外等视觉传感器下，可抽象为机舱和和机身这两个部件。机舱通常为驾驶员和战斗机动力系统的中枢，而机身通常为燃油箱和传动系统的主要区域，二者的毁伤程度决定飞机能否正常飞行。控制模块在视觉传感器的感知范围内可抽象成尾翼和侧翼这两个部件，二者是飞机在空中维持稳定的根本。尾翼的主要作用是控制飞机的飞行或起飞和降落，侧翼用于提供升力，维持飞机在空中的飞行，二者的毁伤程度决定飞机的可控性。通过对每个模块中部件的重要性进行划分，结合目标检测子系统的输出信息和战斗机毁伤评估体系，即可融合各类信息，确定各评估对象的毁伤程度，为决策者提供有关不同部件毁伤情况的毁伤等级评估结果。
基于三角模糊数的毁伤评估体系的建立
由于各个部件的毁伤特征θij在评估目标毁伤效果中具有不同的权重，因此需要合理地为各项毁伤特征分配适当的权重，以综合考虑毁伤信息。在毁伤评估中，三角模糊数可用于表示对被评估物体毁伤程度或破坏程度的不确定性、隶属度和可能性，可以表示为：AAxxx=(,())µ∈X(11)其中，A表示三角模糊数，X表示输入变量x的取值范围，Aµ()x是x在三角形内的隶属度，可以用隶属度函数表示：

其中，µA()0,1x∈[]，abc、、分别表示三角形的左、上、右顶点在X上的取值。如图10所示，当xb=时，x完全隶属于A；当xa≤或xc≥时，x不属于A。
在基于模糊层次分析法的目标整体毁伤评估过程中，使用三角模糊数定义判断矩阵()ijnn×Dd=衡量各部件对于目标整体毁伤的重要性，其中,,ijijijij=abcd为第i个部件与第j个部件相对重要性权重；ijb为第i个部件与第j个部件相对重要性判断中间值；ija为下界值；ijc为上界值。
由于模糊数判断矩阵D使用三角模糊数，需要建立新的计算方法来确定各部件对评估对象的重要性权重。下面是毁伤体系权重的建立方法：
因此，可以根据目标检测头输出的毁伤类别Cdmg和毁伤特征θij和建立的不同部件对于相应评估对象毁伤体系权重向量W，计算得到不同程度毁伤的部件对于评估对象的整体毁伤程度。在毁伤评估体系中，根据评估对象的整体毁伤程度的度量值，可对整体毁伤进行不同毁伤等级的划分，即零毁伤、轻微毁伤、中度毁伤、严重毁伤，将其定义成一个毁伤评估语义集：V={vvvvv12345,,,,}，其中1v到5v根据毁伤程度依次递增，即1v表示零毁伤，5v表示完全毁伤，毁伤等级评定如表2所示。
 
根据表2，可对评估对象的整体毁伤程度进行等级划分，从而为后续的决策提供依据。
基于改进的模糊层次分析法的目标毁伤效果评估
在目标检测头输出检测结果后，送入毁伤评估子系统进行毁伤对象的毁伤等级评定，将评估对象所有的毁伤框的毁伤特征θij依据其对应的部件类别dmgiC向量化，对于毁伤类别dmg0iC≠的毁伤框，令12(,,,)Θ=…θθθk，其中，k为评估对象的部件框数量，Θ中每个元素的取值如下：dmg,0,iijiθiCθ==其他(16)其中，i为不包含dmg0iC=类别的毁伤框索引值。进而计算评估对象的整体毁伤程度，由于Θ中每一个θi反映出的毁伤效果不同，由毁伤体系权重向量W反映，因此可得到评估对象的整体毁伤评估量化值Q：TQ=Θ⋅W(17)其中，Q为该对象整体毁伤评估量化值,反映了毁伤对象的总体毁伤程度，W是本研究通过三角模糊数建立的毁伤体系权重向量，Θ是为对象的毁伤特征向量。
(可以在此处加入神经网络)
对Q根据表2中毁伤等级评定表中的毁伤等级V={vvvvv12345,,,,}进行赋值，得到最终的评估结果。上述过程对毁伤分类器输出的一般毁伤进行了评估，由于存在未知毁伤和零毁伤的特殊情况，因此对这两种特殊情况还要做以下的分析，对于算法2中判定为零毁伤的对象，即不存在毁伤框标志η，其整体毁伤等级评定为1v，即零毁伤；对于毁伤类别为dmg0iC=的毁伤框，则将其反馈到毁伤评估子系统中再评估。
评测指标
（1）毁伤判定准则
毁伤判定准则是毁伤评估的最基本依据和评测指标，描述了各种目标的毁伤等级和相应的毁伤程度。本研究主要采用了基于目标外围的几何形状和基于内在的纹理参数相结合的方法进行评估，并确定评估准则如下：①目标几何和纹理特征均变化不大，则认为目标基本上没受到摧毁，定性为轻度毁伤；②目标几何特征变化较大，纹理变化不大，判断目标受到轻微攻击，但内部结构并未受到巨大打击，定性为中度毁伤；③目标纹理特征变化较大，几何特征变化一般，判定虽然外形维持原状，但内部受损较严重，定性为重度毁伤；④目标几何、纹理特征均受损严重，判断目标受到严重摧毁，定性为报废。为了比较准确的反映目标的毁伤状态，将毁伤等级根据毁伤程度量化为四个级别(各阈值仅供参考)：1)轻度毁伤：毁伤程度60％。（纹理变化率≥40%,相似度≤40%）
（2）准确率、精确率和F1分数
可行性分析（1页）

已有研究基础
学术论文（10-15页）
问题背景（摘要）

系统结构图
定量结果图
定性结果图

	Q.Wang*,M.Chen,F.Nie,andX.Li,“DetectingCoherentGroupsinCrowdScenesbyMultiviewClustering,”IEEETransactionsonPatternAnalysisandMachineIntelligence,vol.42,no.1,pp.46-58,2020.(SIC一区，影响因子24.3)

专利软著（7页）
Xxx
图
项目应用（3页）
